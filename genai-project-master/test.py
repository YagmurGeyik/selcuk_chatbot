import os
import time
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from pymilvus import Collection, connections, utility
from openai import OpenAI

# -----------------------
# CONFIG
# -----------------------
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

MILVUS_HOST = os.getenv("MILVUS_HOST", "localhost")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")

# Senin .env dosyanda COLLECTION_NAME var.
# BazÄ± Ã¶rnek projelerde MILVUS_COLLECTION kullanÄ±lÄ±yor.
COLLECTION_NAME = (
    os.getenv("COLLECTION_NAME")
    or os.getenv("MILVUS_COLLECTION")
    or "rules_qa"
)

EMBED_MODEL = os.getenv("EMBED_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o-mini")

TOP_K = int(os.getenv("TOP_K", "3"))

# SelamlaÅŸma / kÄ±sa mesaj yakalama
GREETING_KEYWORDS = {"merhaba", "selam", "hello", "hi", "iyi gÃ¼nler", "iyi akÅŸamlar", "gÃ¼naydÄ±n"}

# -----------------------
# UI
# -----------------------
st.set_page_config(page_title="Milvus Q&A Chatbot", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ Ãœniversite Soru-Cevap AsistanÄ±")

if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEY bulunamadÄ±. .env dosyanÄ± kontrol et.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# -----------------------
# INIT MILVUS
# -----------------------
@st.cache_resource
def init_milvus():
    connections.connect(alias="default", host=MILVUS_HOST, port=MILVUS_PORT)

    if not utility.has_collection(COLLECTION_NAME):
        st.error(f"'{COLLECTION_NAME}' koleksiyonu bulunamadÄ±. Ã–nce 'python ingest.py' Ã§alÄ±ÅŸtÄ±r.")
        st.stop()

    col = Collection(COLLECTION_NAME)

    # Åemadaki alanlarÄ± oku (header var mÄ±? vektÃ¶r alan adÄ± ne?)
    field_names = {f.name for f in col.schema.fields}

    # Projene gÃ¶re vektÃ¶r alanÄ± bazen "vector", bazen "vector_context" oluyor.
    if "vector_context" in field_names:
        vector_field = "vector_context"
    elif "vector" in field_names:
        vector_field = "vector"
    else:
        st.error(f"Koleksiyon ÅŸemasÄ±nda vektÃ¶r alanÄ± bulunamadÄ±. Bulunan alanlar: {sorted(field_names)}")
        st.stop()

    has_header = "header" in field_names
    has_source = "source" in field_names
    has_context = "context" in field_names

    if not has_context:
        st.error(f"Koleksiyon ÅŸemasÄ±nda 'context' alanÄ± yok. Bulunan alanlar: {sorted(field_names)}")
        st.stop()

    # Index yoksa oluÅŸtur (vektÃ¶r alanÄ±na gÃ¶re)
    if len(col.indexes) == 0:
        with st.spinner("ğŸ”§ Index oluÅŸturuluyor..."):
            col.create_index(
                field_name=vector_field,
                index_params={"metric_type": "IP", "index_type": "AUTOINDEX", "params": {}}
            )
            # index oluÅŸana kadar bekle
            while True:
                progress = utility.index_building_progress(COLLECTION_NAME)
                if progress.get("indexed_rows", 0) == progress.get("total_rows", 1):
                    break
                time.sleep(1)

    col.load()
    return col, vector_field, has_header, has_source

collection, VECTOR_FIELD, HAS_HEADER, HAS_SOURCE = init_milvus()

# -----------------------
# RAG
# -----------------------
def embed_text(text: str):
    emb = client.embeddings.create(model=EMBED_MODEL, input=text)
    return emb.data[0].embedding

def search_milvus(query_text: str, top_k: int = TOP_K):
    query_vector = embed_text(query_text)

    # output_fields ÅŸemaya gÃ¶re seÃ§ilsin (header yoksa istemeyelim)
    output_fields = ["context"]
    if HAS_HEADER:
        output_fields.append("header")
    if HAS_SOURCE:
        output_fields.append("source")

    results = collection.search(
        data=[query_vector],
        anns_field=VECTOR_FIELD,
        param={"metric_type": "IP", "params": {"nprobe": 10}},
        limit=top_k,
        output_fields=output_fields
    )

    hits = []
    for hit in results[0]:
        hits.append({
            "context": hit.entity.get("context"),
            "header": hit.entity.get("header") if HAS_HEADER else None,
            "source": hit.entity.get("source") if HAS_SOURCE else None,
            "score": float(hit.distance),
        })
    return hits

def ask_gpt(question: str, contexts):
    # âœ… KullanÄ±cÄ±ya pdf gÃ¶stermeyeceÄŸiz â†’ prompt iÃ§inde de dosya adÄ± istemiyoruz
    # Contextleri sadece iÃ§erik olarak veriyoruz.
    parts = []
    for i, c in enumerate(contexts):
        if c.get("header"):
            parts.append(f"{i+1}) {c['header']}\n{c['context']}")
        else:
            parts.append(f"{i+1}) {c['context']}")
    context_text = "\n\n".join(parts)

    prompt = f"""
AÅŸaÄŸÄ±daki yÃ¶netmelik parÃ§alarÄ±nÄ± kullanarak soruyu cevapla.

YÃ–NETMELÄ°K PARÃ‡ALARI:
{context_text}

SORU: {question}

KURALLAR:
- Cevap TÃ¼rkÃ§e, kÄ±sa ve net olsun.
- Sadece SelÃ§uk Ãœniversitesi ile ilgili yÃ¶netmelik/iÅŸlem sorularÄ±na cevap ver.
- Okulla ilgisizse aynen ÅŸunu sÃ¶yle: "ÃœzgÃ¼nÃ¼m yalnÄ±zca SelÃ§uk Ãœniversitesi ile ilgili sorulara cevap verebilirim."
- Cevapta dosya adÄ±, PDF adÄ±, kÃ¶ÅŸeli parantez (Ã¶rn. [xxx.pdf]) veya kaynak etiketi yazma.
- SelamlaÅŸma gibi mesajlarda kullanÄ±cÄ±yÄ± yÃ¶nlendir.

YANIT:
"""

    completion = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[
            {"role": "system", "content": "Sen SelÃ§uk Ãœniversitesi Ã¶ÄŸrenci iÅŸlerinde uzman bir asistansÄ±n."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    return completion.choices[0].message.content.strip()

# -----------------------
# UI CHAT
# -----------------------
st.markdown("Sorunu yaz ğŸ‘‡ YÃ¶netmeliklerden bulup cevaplayacaÄŸÄ±m.")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

question = st.text_input("ğŸ“ Soru:", placeholder="Ã–rn: Ders kaydÄ± nasÄ±l yapÄ±lÄ±r?")

if st.button("ğŸš€ GÃ¶nder") and question:
    q = question.strip()
    q_lower = q.lower().strip()

    with st.spinner("YanÄ±t hazÄ±rlanÄ±yor..."):
        # 1) SelamlaÅŸma yakala (Milvus aramasÄ± yapmadan)
        if q_lower in GREETING_KEYWORDS:
            answer = "Merhaba ğŸ‘‹ SelÃ§uk Ãœniversitesi ile ilgili bir sorunuz varsa yardÄ±mcÄ± olabilirim."
        else:
            contexts = search_milvus(q, top_k=TOP_K)

            # Context gelmezse (Ã§ok nadir) gÃ¼venli cevap
            if not contexts:
                answer = "Bu konuda yÃ¶netmeliklerde net bir bilgi bulamadÄ±m. Sorunu biraz daha detaylandÄ±rabilir misin?"
            else:
                answer = ask_gpt(q, contexts)

        st.session_state.chat_history.append(("ğŸ‘¤", q))
        st.session_state.chat_history.append(("ğŸ¤–", answer))

for role, text in st.session_state.chat_history:
    if role == "ğŸ‘¤":
        st.markdown(f"**{role}**: {text}")
    else:
        st.success(f"**{role}**: {text}")
